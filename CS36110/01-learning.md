Learning
========

Knowledge is gained through learning from experience. Normally to apply knowledge we have to makes some form of assumtions, we call this bias in IL. Therefore our knowledge is not always correct.

We can learn from both sucess and failure.

Learning is an abstract process, we cannot formalise how we as humans actually learn.

AI Systems
----------

TODO image here.

The advantages of this are as follows:
* This is often more accurate than humans.
* Humans are often incapable of expressing the result.
* Automatic method to search for the hypothesis explains the data.
* Cheap and flexible.

However the downsides are that:
* There's a need for a lot of labelled data.
* Error-prone and inheritantly imperfect.
* Difficult to discern what has actually been learnt.

One important tennant of IL is that data is cheap and abudant, but knowledge is rare and expensive. Thus learning from examples is the most common form of learning.

To have achived learning you must improve the performance of the system in some way.

The training data takes the form of an input:output mapping. The input is usually some form of vector and the output can take the form of a real, discrete or categorical value.

If $output \in R$ then the algorithm is ??? (I turned off here).

Learning is supervised is the output of the training data is known.

We define this experience in the form

$y = f(x)$

Where: $y$ is the outcome and $x$ is the parameters. We use $f$ to map 